---
title: 'Proteina'
---

I was a advisor providing high-level feedback and guidance. The Nvidia team explored the "bitter lesson" for protein generation by scaling up non-equivariant diffusion models with a Diffusion Transformer architecture up to 400 million parameters and datasets up to 21 million structures. They used classifier-free guidance, autoguidance, and LoRA to guide generation towards desired protein topologies. The model demonstrated state-of-the-art generation quality and diversity while being able to extend to longer proteins up to 800 residues. Other methods often struggle at scaling up to proteins beyond 400 residues (see graph).
